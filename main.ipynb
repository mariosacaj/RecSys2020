{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "7Ifkd08Lq3wR",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## RECSYS CHALLENGE 2020 ##\n",
    "# Evaluation or scoring?\n",
    "eval = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mDejDEXq3wW",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Loading from CSV files...\n",
    "from RecLib.DataLoad import *\n",
    "UCM_age, ICM_subclass, ICM_asset, ICM_price, UCM_region, target_users, URM = dataLoad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4FzKl-xq3wc",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sps\n",
    "URM = URM.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aODXsh3XsyJA",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Split dataset (train % of .9999 gives similar performance on test set and competition set)\n",
    "from Notebooks_utils.data_splitter import train_test_holdout\n",
    "URM_train, URM_test = train_test_holdout(URM, train_perc = 0.8)\n",
    "\n",
    "\n",
    "if not eval:\n",
    "    URM_train = URM\n",
    "else:\n",
    "    from Base.Evaluation.Evaluator import EvaluatorHoldout\n",
    "    from RecLib.Evaluate import *\n",
    "    evaluator_validation = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load Item & User Content matrix\n",
    "ICM, UCM = contentMatrixLoad(URM_train, ICM_subclass, ICM_price, ICM_asset, UCM_age, UCM_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to read memory status: list index out of range\n",
      "SLIM_BPR_Recommender: Epoch 1 of 300. Elapsed time 0.05 sec\n",
      "SLIM_BPR_Recommender: Epoch 76 of 300. Elapsed time 4.29 sec\n",
      "SLIM_BPR_Recommender: Epoch 151 of 300. Elapsed time 8.79 sec\n",
      "SLIM_BPR_Recommender: Epoch 226 of 300. Elapsed time 12.78 sec\n",
      "SLIM_BPR_Recommender: Terminating at epoch 300. Elapsed time 23.41 sec\n",
      "Deallocating Cython objects\n",
      "EvaluatorHoldout: Processed 20328 ( 100.00% ) in 12.52 sec. Users per second: 1624\n",
      "('epoch, batch, topK, lr :300 50 10 0.001', 0.040918383661020505)\n"
     ]
    }
   ],
   "source": [
    "# SLIM BPR Recommender\n",
    "if True:\n",
    "    from SLIM_BPR.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython \n",
    "    slim_rec = SLIM_BPR_Cython(URM_train, recompile_cython=False, verbose = False)\n",
    "    MAP_LIST = []\n",
    "    epochsList = [300]\n",
    "    batchSize = [50]\n",
    "    tklist = [10]\n",
    "    lrs = [1e-3]\n",
    "\n",
    "    for epochsN in epochsList:\n",
    "        for bs in batchSize:\n",
    "            for tk in tklist:\n",
    "                for lr in lrs:\n",
    "                    do_not_display_hystory = slim_rec.fit(epochs=epochsN, batch_size=bs, sgd_mode='adagrad', learning_rate=lr, topK = tk)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(slim_rec))[0][10]\n",
    "                        MAP_LIST.append(('epoch, batch, topK, lr :' + str(epochsN) + ' ' + str(bs)+ ' ' + str(tk) + ' ' + str(lr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 18495 ( 100 % ), 7147.59 column/sec, elapsed time 0.04 min\n",
      "EvaluatorHoldout: Processed 20328 ( 100.00% ) in 10.65 sec. Users per second: 1908\n",
      "('topK, shrink :3 10', 0.013960042392195521)\n"
     ]
    }
   ],
   "source": [
    "# ItemKNN Content Based Filtering\n",
    "if True:\n",
    "    from KNN.ItemKNNCBFRecommender import ItemKNNCBFRecommender \n",
    "    itemKNNCBF = ItemKNNCBFRecommender(URM_train, ICM)\n",
    "    MAP_LIST = []\n",
    "    tklist = [3]\n",
    "    shrinklist = [10]\n",
    "\n",
    "    for tk in tklist:\n",
    "        for sr in shrinklist:\n",
    "            itemKNNCBF.fit(shrink=sr, topK = tk, similarity = 'cosine')\n",
    "            if eval:\n",
    "                dict_scores = (evaluator_validation.evaluateRecommender(itemKNNCBF))[0][10]\n",
    "                MAP_LIST.append(('topK, shrink :' + str(tk) + ' ' + str(sr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDRecommender: Computing SVD decomposition...\n",
      "PureSVDRecommender: Computing SVD decomposition... Done!\n",
      "EvaluatorHoldout: Processed 20328 ( 100.00% ) in 16.77 sec. Users per second: 1212\n",
      "[('num factors :400', 0.024527447339383654)]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "if True:\n",
    "    from MatrixFactorization.PureSVDRecommender import PureSVDRecommender \n",
    "    pureSVD = PureSVDRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    nfactorlist = [400]\n",
    "\n",
    "    for n in nfactorlist:\n",
    "        pureSVD.fit(num_factors=n, random_seed = None)\n",
    "        if eval:\n",
    "            dict_scores = (evaluator_validation.evaluateRecommender(pureSVD))[0][10]\n",
    "            MAP_LIST.append(('num factors :' + str(n) , dict_scores['MAP']))\n",
    "    if eval:\n",
    "        print(MAP_LIST)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 30911 ( 100 % ), 1656.55 column/sec, elapsed time 0.31 min\n",
      "EvaluatorHoldout: Processed 20328 ( 100.00% ) in 20.39 sec. Users per second: 997\n",
      "[('topK, shrink :2500 10', 0.00865447788326124)]\n"
     ]
    }
   ],
   "source": [
    "# UserKNN Content Based Filtering\n",
    "if True:\n",
    "    from KNN.UserKNNCBFRecommender import UserKNNCBFRecommender \n",
    "    userKNNCBF = UserKNNCBFRecommender(URM_train, UCM)\n",
    "    MAP_LIST = []\n",
    "    tklist = [2500]\n",
    "    shrinklist = [10]\n",
    "\n",
    "    for tk in tklist:\n",
    "        for sr in shrinklist:\n",
    "            userKNNCBF.fit(shrink=sr, topK = tk, similarity = 'cosine')\n",
    "            if eval:\n",
    "                dict_scores = (evaluator_validation.evaluateRecommender(userKNNCBF))[0][10]\n",
    "                MAP_LIST.append(('topK, shrink :' + str(tk) + ' ' + str(sr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        print(MAP_LIST)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightFM Recommender\n",
    "if False:\n",
    "    from RecLib.LFMRec import LFM \n",
    "    lfm_rec = LFM(URM_train)\n",
    "    MAP_LIST = []\n",
    "    epochsList = [20]\n",
    "    batchSize = [50]\n",
    "    tklist = [10]\n",
    "    lrs = [0.05]\n",
    "    losses=['bpr']\n",
    "\n",
    "    for epochsN in epochsList:\n",
    "        for loss in losses:\n",
    "            for tk in tklist:\n",
    "                for lr in lrs:\n",
    "                    do_not_display_hystory = lfm_rec.fit(epochs=epochsN, no_components=10,\n",
    "            k=5,\n",
    "            n=10,\n",
    "            learning_schedule=\"adagrad\",\n",
    "            loss=loss,\n",
    "            learning_rate=lr,\n",
    "            rho=0.95,\n",
    "            epsilon=1e-6,\n",
    "            item_alpha=0.0,\n",
    "            user_alpha=0.0,\n",
    "            max_sampled=10,\n",
    "            random_state=None, num_threads=1,\n",
    "            verbose=False)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(lfm_rec))[0][10]\n",
    "                        MAP_LIST.append(('epoch, loss, lr :' + str(epochsN) + ' ' + loss + ' '  + str(lr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# UserKNN Collaborative Filtering\n",
    "if False:\n",
    "    from KNN.UserKNNCFRecommender import UserKNNCFRecommender \n",
    "    userKNNCF = UserKNNCFRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    tklist = [600]\n",
    "    shrinklist = [5]\n",
    "\n",
    "    for tk in tklist:\n",
    "        for sr in shrinklist:\n",
    "            userKNNCF.fit(shrink=sr, topK = tk, similarity = 'cosine')\n",
    "            if eval:\n",
    "                dict_scores = (evaluator_validation.evaluateRecommender(userKNNCF))[0][10]\n",
    "                MAP_LIST.append(('topK, shrink :' + str(tk) + ' ' + str(sr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Pm7oY2Zx6Soy",
    "outputId": "d56a6477-e677-4dbe-db85-49c119d4b348",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 18495 ( 100 % ), 7760.86 column/sec, elapsed time 0.04 min\n",
      "EvaluatorHoldout: Processed 20328 ( 100.00% ) in 10.52 sec. Users per second: 1932\n",
      "MAP: 0.04484938014762729\n"
     ]
    }
   ],
   "source": [
    "# ItemKNN Collaborative Filtering\n",
    "if True:\n",
    "    from KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "    itemKNN = ItemKNNCFRecommender(URM_train)\n",
    "    itemKNN.fit(shrink=50, topK=5)\n",
    "\n",
    "    if eval:\n",
    "        evaluator_validation = EvaluatorHoldout(URM_test, cutoff_list=[10])\n",
    "        results, _ = evaluator_validation.evaluateRecommender(itemKNN)\n",
    "        print('MAP: ' + str(results[10][\"MAP\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import xgboost as xgb\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=3)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    params = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # step for each iteration\n",
    "    'silent': 1, # keep it quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3, # the number of classes \n",
    "    'eval_metric': 'merror'} # evaluation metric \n",
    "\n",
    "    num_round = 20  # the number of training iterations (number of trees)\n",
    "    model = xgb.train(params,\n",
    "                  dtrain,\n",
    "                  num_round,\n",
    "                  verbose_eval=2,\n",
    "                  evals=[(dtrain, 'train'), (dval, 'validation')],\n",
    "                  early_stopping_rounds=20)\n",
    "    from sklearn.metrics import precision_score\n",
    "\n",
    "    preds = model.predict(dtest)\n",
    "    best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "    print(\"Precision: {:.2f} %\".format(precision_score(y_test, best_preds, average='macro')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 20328 ( 100.00% ) in 10.18 sec. Users per second: 1997\n",
      "('Normalize, topK, alpha :True 30 0.4', 0.046528166488274715)\n"
     ]
    }
   ],
   "source": [
    "# Graph Based\n",
    "if True:\n",
    "    from GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "    p3alpha_rec = P3alphaRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    similList = [True]\n",
    "    tklist = [30]\n",
    "    alphaList = [0.4]\n",
    "\n",
    "    for simil in similList:\n",
    "        for tk in tklist:\n",
    "            for alpha in alphaList:\n",
    "                do_not_display_hystory = p3alpha_rec.fit(topK=tk, alpha=alpha, normalize_similarity=simil)\n",
    "                if eval:\n",
    "                    dict_scores = (evaluator_validation.evaluateRecommender(p3alpha_rec))[0][10]\n",
    "                    MAP_LIST.append(('Normalize, topK, alpha :' + str(simil)+ ' ' + str(tk) + ' ' + str(alpha), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 20328 ( 100.00% ) in 10.35 sec. Users per second: 1964\n",
      "('Normalize, topK, alpha, beta :True 50 0.4 0.1', 0.04757368003245156)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "    p3beta_rec = RP3betaRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    betaList = [0.1]\n",
    "    similList = [True]\n",
    "    tklist = [50]\n",
    "    alphaList = [0.4]\n",
    "\n",
    "    for beta in betaList:\n",
    "        for simil in similList:\n",
    "            for tk in tklist:\n",
    "                for alpha in alphaList:\n",
    "                    do_not_display_hystory = p3beta_rec.fit(topK=tk, alpha=alpha, beta=beta, normalize_similarity=simil)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(p3beta_rec))[0][10]\n",
    "                        MAP_LIST.append(('Normalize, topK, alpha, beta :' + str(simil)+ ' ' + str(tk) + ' ' + str(alpha) + ' ' + str(beta), dict_scores['MAP']))\n",
    "\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 5001 ( 24.60% ) in 33.38 sec. Users per second: 150\n",
      "EvaluatorHoldout: Processed 11001 ( 54.12% ) in 1.11 min. Users per second: 165\n",
      "EvaluatorHoldout: Processed 17001 ( 83.63% ) in 1.62 min. Users per second: 175\n",
      "EvaluatorHoldout: Processed 20328 ( 100.00% ) in 1.82 min. Users per second: 186\n",
      "EvaluatorHoldout: Processed 5001 ( 24.60% ) in 30.03 sec. Users per second: 167\n",
      "EvaluatorHoldout: Processed 11001 ( 54.12% ) in 1.00 min. Users per second: 183\n",
      "EvaluatorHoldout: Processed 17001 ( 83.63% ) in 1.51 min. Users per second: 188\n",
      "EvaluatorHoldout: Processed 20328 ( 100.00% ) in 1.85 min. Users per second: 183\n",
      "EvaluatorHoldout: Processed 5001 ( 24.60% ) in 33.34 sec. Users per second: 150\n",
      "EvaluatorHoldout: Processed 11001 ( 54.12% ) in 1.10 min. Users per second: 167\n",
      "EvaluatorHoldout: Processed 17001 ( 83.63% ) in 1.61 min. Users per second: 176\n",
      "EvaluatorHoldout: Processed 20328 ( 100.00% ) in 1.81 min. Users per second: 187\n",
      "('alpha, beta, gamma, delta, epsilon :(0.7, 0.1, 0.4, 0.05, 0.3, 1)', 0.04854151928218495)\n",
      "('alpha, beta, gamma, delta, epsilon :(0.5, 0.1, 0.4, 0.05, 1, 3)', 0.048679266727607355)\n",
      "('alpha, beta, gamma, delta, epsilon :(0.7, 0.1, 0.4, 0.05, 0.5, 1)', 0.04877637018703297)\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Recommender\n",
    "from RecLib.HybridRecommender import *\n",
    "if True:\n",
    "    params = [(0.7, 0.1, 0.4, 0.05, 0.5, 1)]\n",
    "    MAP_LIST = []\n",
    "    for param in params:\n",
    "                hybridrecommender = HybridRecommender(URM_train, userKNNCBF, itemKNN, itemKNNCBF, slim_rec, pureSVD, p3alpha_rec, p3beta_rec)\n",
    "                hybridrecommender.fit(*param)\n",
    "                if eval:\n",
    "                    dict_scores = (evaluator_validation.evaluateRecommender(hybridrecommender))[0][10]\n",
    "                    MAP_LIST.append(('alpha, beta, gamma, delta, epsilon :' + str(param), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate performance of a recommender against users with 0,1,...,itrMax interactions\n",
    "rec_to_eval = hybridrecommender\n",
    "itrMax = 2\n",
    "\n",
    "if eval:\n",
    "    evaluateAgainstUsers(rec_to_eval, itrMax, URM_train, URM_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Compare different recommenders\n",
    "recommendersToCompare = [itemKNN, p3alpha_rec, p3beta_rec, hybridrecommender]\n",
    "\n",
    "if eval:\n",
    "    from RecLib.Evaluate import *\n",
    "    compare(URM_train, URM_test, recommendersToCompare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYQRvvikMJVN",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "final_Rec = hybridrecommender\n",
    "\n",
    "if not eval:\n",
    "    output = []\n",
    "    for user_id in target_users:\n",
    "        output.append((user_id, final_Rec.recommend(user_id, cutoff=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5TyQsg9TAwz",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Writedown results\n",
    "\n",
    "if not eval:\n",
    "    import csv\n",
    "    with open('submission.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"user_id\", \"item_list\"])\n",
    "        for row in output:\n",
    "          ranking = ''\n",
    "          for val in row[1]:\n",
    "            ranking = ranking + str(val) + ' '\n",
    "          writer.writerow([row[0], ranking[:-1]])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sacajrota.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
