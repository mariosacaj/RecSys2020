{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "7Ifkd08Lq3wR",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## RECSYS CHALLENGE 2020 ##\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from Notebooks_utils.data_splitter import train_test_holdout\n",
    "\n",
    "# Evaluation or scoring?\n",
    "eval = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mDejDEXq3wW",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Loading from CSV files...\n",
    "from RecLib.DataLoad import *\n",
    "UCM_age, ICM_subclass, ICM_asset, ICM_price, UCM_region, target_users, URM = dataLoad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4FzKl-xq3wc",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "URM = URM.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aODXsh3XsyJA",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Split dataset (train % of .9999 gives similar performance on test set and competition set)\n",
    "URM_train, URM_test = train_test_holdout(URM, train_perc = 0.8)\n",
    "\n",
    "if not eval:\n",
    "    URM_train = URM\n",
    "else:\n",
    "    from Base.Evaluation.Evaluator import EvaluatorHoldout\n",
    "    from RecLib.Evaluate import *\n",
    "    evaluator_validation = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load Item & User Content matrix\n",
    "ICM, UCM = contentMatrixLoad(URM_train, ICM_subclass, ICM_price, ICM_asset, UCM_age, UCM_region, bins=0, no_price = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Processed 5550 ( 30.01% ) in 5.00 min. Items per second: 18.49\n",
      "SLIMElasticNetRecommender: Processed 10649 ( 57.58% ) in 10.00 min. Items per second: 17.74\n",
      "SLIMElasticNetRecommender: Processed 18318 ( 99.04% ) in 15.00 min. Items per second: 20.35\n",
      "SLIMElasticNetRecommender: Processed 18495 ( 100.00% ) in 15.12 min. Items per second: 20.39\n",
      "SLIMElasticNetRecommender: Saving model in file 'wholeDataset_SLIMElasticNetRecommender_model'\n",
      "SLIMElasticNetRecommender: Saving complete\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from SLIM_ElasticNet.SLIMElasticNetRecommender import SLIMElasticNetRecommender\n",
    "    SLIMElasticNet = SLIMElasticNetRecommender(URM_train.tocsr())\n",
    "    if True or not eval:\n",
    "        MAP_LIST = []\n",
    "        tklist = [60]\n",
    "        penalties = [1]\n",
    "        alphas = [1e-4]\n",
    "        tol = [1e-5]\n",
    "        max_iter = [100]\n",
    "        positives = [True]\n",
    "        warm_start = [True]\n",
    "        for tk in tklist:\n",
    "            for penalty in penalties:\n",
    "                for alpha in alphas:\n",
    "                    for t in tol:\n",
    "                        for iters in max_iter:\n",
    "                            for positivity in positives:\n",
    "                                for ws in warm_start:\n",
    "                                    SLIMElasticNet.fit(l1_ratio=penalty, alpha = alpha, positive_only=positivity, topK = tk, warm_start = ws,tol = 1e-4, max_iter=100)\n",
    "                                    if eval:\n",
    "                                        dict_scores = (evaluator_validation.evaluateRecommender(SLIMElasticNet))[0][10]\n",
    "                                        MAP_LIST.append(('tol, positives, warm_start, iterations :' + str(t) + ' ' + str(positivity) + ' ' + str(ws) + ' ' + str(iters), dict_scores['MAP']))\n",
    "        if eval:\n",
    "            sortMap(MAP_LIST)\n",
    "        SLIMElasticNet.save_model('.')\n",
    "    else:\n",
    "        SLIMElasticNet.load_model('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to read memory status: list index out of range\n",
      "SLIM_BPR_Recommender: Epoch 1 of 300. Elapsed time 0.06 sec\n",
      "SLIM_BPR_Recommender: Epoch 76 of 300. Elapsed time 4.63 sec\n",
      "SLIM_BPR_Recommender: Epoch 151 of 300. Elapsed time 9.37 sec\n",
      "SLIM_BPR_Recommender: Epoch 226 of 300. Elapsed time 13.97 sec\n",
      "SLIM_BPR_Recommender: Terminating at epoch 300. Elapsed time 25.02 sec\n",
      "Deallocating Cython objects\n"
     ]
    }
   ],
   "source": [
    "# SLIM BPR Recommender\n",
    "if True:\n",
    "    from SLIM_BPR.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython \n",
    "    slim_rec = SLIM_BPR_Cython(URM_train, recompile_cython=False, verbose = False)\n",
    "    MAP_LIST = []\n",
    "    epochsList = [300]\n",
    "    batchSize = [50]\n",
    "    tklist = [10]\n",
    "    lrs = [1e-3]\n",
    "\n",
    "    for epochsN in epochsList:\n",
    "        for bs in batchSize:\n",
    "            for tk in tklist:\n",
    "                for lr in lrs:\n",
    "                    do_not_display_hystory = slim_rec.fit(epochs=epochsN, batch_size=bs, sgd_mode='adagrad', learning_rate=lr, topK = tk)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(slim_rec))[0][10]\n",
    "                        MAP_LIST.append(('epoch, batch, topK, lr :' + str(epochsN) + ' ' + str(bs)+ ' ' + str(tk) + ' ' + str(lr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 18495 ( 100 % ), 5373.27 column/sec, elapsed time 0.06 min\n"
     ]
    }
   ],
   "source": [
    "# ItemKNN Content Based Filtering\n",
    "if True:\n",
    "    from sklearn import preprocessing\n",
    "    from KNN.ItemKNNCBFRecommender import ItemKNNCBFRecommender \n",
    "    MAP_LIST = []\n",
    "    tklist = [3]\n",
    "    shrinklist = [10]\n",
    "    for bins in [5]:\n",
    "        for tk in tklist:\n",
    "            for sr in shrinklist:\n",
    "                le = preprocessing.KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='kmeans')\n",
    "                X = np.reshape(np.ediff1d(URM_train.tocsc().indptr), (-1, 1))\n",
    "                le.fit_transform(X)\n",
    "                classList = le.transform(X)\n",
    "                ones = np.ones(len(classList))\n",
    "                ICM_pop = coo_matrix((ones, (np.arange(0, URM_train.shape[1]), classList.reshape(-1,))), shape=(URM_train.shape[1], bins))\n",
    "                ICM_pop = ICM_pop.tocsr()\n",
    "                ICM_mod = sps.hstack([ICM, ICM_pop], format='csr')\n",
    "                #ICM_mod = sps.hstack([ICM_mod, ICM_price], format='csr')\n",
    "                itemKNNCBF = ItemKNNCBFRecommender(URM_train, ICM_mod)\n",
    "                itemKNNCBF.fit(shrink=sr, topK = tk, similarity = 'cosine')\n",
    "                if eval:\n",
    "                    dict_scores = (evaluator_validation.evaluateRecommender(itemKNNCBF))[0][10]\n",
    "                    MAP_LIST.append(('topK, shrink, bins :' + str(tk) + ' ' + str(sr) + ' '+str(bins), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDRecommender: Computing SVD decomposition...\n",
      "PureSVDRecommender: Computing SVD decomposition... Done!\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from MatrixFactorization.PureSVDRecommender import PureSVDRecommender \n",
    "    pureSVD = PureSVDRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    nfactorlist = [400]\n",
    "\n",
    "    for n in nfactorlist:\n",
    "        pureSVD.fit(num_factors=n, random_seed = None)\n",
    "        if eval:\n",
    "            dict_scores = (evaluator_validation.evaluateRecommender(pureSVD))[0][10]\n",
    "            MAP_LIST.append(('num factors :' + str(n) , dict_scores['MAP']))\n",
    "    if eval:\n",
    "        print(MAP_LIST)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNK_SVD: Epoch 1 of 300. Elapsed time 0.47 sec\n",
      "FUNK_SVD: Epoch 76 of 300. Elapsed time 34.88 sec\n",
      "FUNK_SVD: Epoch 151 of 300. Elapsed time 1.20 min\n",
      "FUNK_SVD: Epoch 226 of 300. Elapsed time 1.85 min\n",
      "FUNK_SVD: Terminating at epoch 300. Elapsed time 2.45 min\n",
      "EvaluatorHoldout: Processed 20320 ( 100.00% ) in 21.83 sec. Users per second: 931\n",
      "('epoch, batch, topK, lr :300 50 10 0.001', 0.00017416091682736083)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from MatrixFactorization.Cython.MatrixFactorization_Cython import *\n",
    "    funkSVD = MatrixFactorization_FunkSVD_Cython(URM_train, recompile_cython=False, verbose = False)\n",
    "    MAP_LIST = []\n",
    "    epochsList = [300]\n",
    "    batchSize = [50]\n",
    "    tklist = [10]\n",
    "    lrs = [1e-3]\n",
    "\n",
    "    for epochsN in epochsList:\n",
    "        for bs in batchSize:\n",
    "            for tk in tklist:\n",
    "                for lr in lrs:\n",
    "                    do_not_display_hystory = funkSVD.fit(epochs=epochsN, batch_size=bs, sgd_mode='adagrad', learning_rate=lr, num_factors=10)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(funkSVD))[0][10]\n",
    "                        MAP_LIST.append(('epoch, batch, topK, lr :' + str(epochsN) + ' ' + str(bs)+ ' ' + str(tk) + ' ' + str(lr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IALSRecommender: Epoch 1 of 300. Elapsed time 17.74 min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-42bbc6a1e32e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mMAP_LIST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_factors\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#[10, 20, 35, 50, 70, 100, 150, 200, 400, 600]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_factors\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnum_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdict_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mevaluator_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluateRecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PycharmProjects/RecSys_Course_AT_PoliMi/MatrixFactorization/IALSRecommender.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, num_factors, confidence_scaling, alpha, epsilon, reg, init_mean, init_std, **earlystopping_kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         self._train_with_early_stopping(epochs,\n\u001b[1;32m     89\u001b[0m                                         \u001b[0malgorithm_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRECOMMENDER_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                                         **earlystopping_kwargs)\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PycharmProjects/RecSys_Course_AT_PoliMi/Base/Incremental_Training_Early_Stopping.py\u001b[0m in \u001b[0;36m_train_with_early_stopping\u001b[0;34m(self, epochs_max, epochs_min, validation_every_n, stop_on_validation, validation_metric, lower_validations_allowed, evaluator_object, algorithm_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mepochs_current\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepochs_max\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconvergence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# If no validation required, always keep the latest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PycharmProjects/RecSys_Course_AT_PoliMi/MatrixFactorization/IALSRecommender.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, num_epoch)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0muser_confidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_pos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_profile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_confidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITEM_factors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# fit item factors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PycharmProjects/RecSys_Course_AT_PoliMi/MatrixFactorization/IALSRecommender.py\u001b[0m in \u001b[0;36m_update_row\u001b[0;34m(self, interaction_profile, interaction_confidence, Y, YtY)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYtY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularization_diagonal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_interactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteraction_confidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/RecSys_Course_AT_PoliMi/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from MatrixFactorization.IALSRecommender import IALSRecommender\n",
    "ials = IALSRecommender(URM_train)\n",
    "MAP_LIST = []\n",
    "for num_factors in [600]: #[10, 20, 35, 50, 70, 100, 150, 200, 400, 600]\n",
    "    ials.fit(num_factors= num_factors)\n",
    "    if eval:\n",
    "        dict_scores = (evaluator_validation.evaluateRecommender(ials))[0][10]\n",
    "        MAP_LIST.append(('num_factors :' + str(num_factors), dict_scores['MAP']))\n",
    "if eval:\n",
    "    sortMap(MAP_LIST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASY_SVD: Epoch 1 of 300. Elapsed time 2.31 sec\n",
      "ASY_SVD: Epoch 76 of 300. Elapsed time 2.64 min\n",
      "ASY_SVD: Epoch 151 of 300. Elapsed time 5.23 min\n",
      "ASY_SVD: Epoch 226 of 300. Elapsed time 7.88 min\n",
      "ASY_SVD: Terminating at epoch 300. Elapsed time 10.53 min\n",
      "EvaluatorHoldout: Processed 20320 ( 100.00% ) in 18.26 sec. Users per second: 1113\n",
      "('epoch, batch, topK, lr :300 50 10 0.001', 0.00010585070095404737)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from MatrixFactorization.Cython.MatrixFactorization_Cython import *\n",
    "    asySVD = MatrixFactorization_AsySVD_Cython(URM_train, recompile_cython=False, verbose = False)\n",
    "    MAP_LIST = []\n",
    "    epochsList = [300]\n",
    "    batchSize = [50]\n",
    "    tklist = [10]\n",
    "    lrs = [1e-3]\n",
    "\n",
    "    for epochsN in epochsList:\n",
    "        for bs in batchSize:\n",
    "            for tk in tklist:\n",
    "                for lr in lrs:\n",
    "                    do_not_display_hystory = asySVD.fit(num_factors=10)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(asySVD))[0][10]\n",
    "                        MAP_LIST.append(('epoch, batch, topK, lr :' + str(epochsN) + ' ' + str(bs)+ ' ' + str(tk) + ' ' + str(lr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b723146a396f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0muserKNNCBF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUserKNNCBFRecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURM_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUCM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0muserKNNCBF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshrink\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mdict_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mevalTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluateRecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserKNNCBF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PycharmProjects/RecSys_Course_AT_PoliMi/KNN/UserKNNCBFRecommender.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, topK, shrink, similarity, normalize, feature_weighting, **similarity_args)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompute_Similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUCM_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msimilarity_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PycharmProjects/RecSys_Course_AT_PoliMi/Base/Similarity/Compute_Similarity.py\u001b[0m in \u001b[0;36mcompute_similarity\u001b[0;34m(self, **args)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_similarity_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mCompute_Similarity_Cython.pyx\u001b[0m in \u001b[0;36mCompute_Similarity_Cython.Compute_Similarity_Cython.compute_similarity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/RecSys_Course_AT_PoliMi/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_argpartition_dispatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'introselect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# UserKNN Content Based Filtering\n",
    "augment_with_profile_lenght = True\n",
    "from sklearn import preprocessing\n",
    "if eval:\n",
    "    to_compute_mask = np.ediff1d(URM_train.tocsr().indptr) == 0\n",
    "    to_ignore_mask = np.invert(to_compute_mask)\n",
    "    to_ignore = np.arange(URM_train.shape[0])[to_ignore_mask]\n",
    "    evalTest = EvaluatorHoldout(URM_test, cutoff_list=[10], ignore_users=to_ignore)\n",
    "\n",
    "if True:\n",
    "    from KNN.UserKNNCBFRecommender import UserKNNCBFRecommender \n",
    "    MAP_LIST = []\n",
    "    tklist = [2700]\n",
    "    shrinklist = [10]\n",
    "    \n",
    "    for tk in tklist:\n",
    "        for sr in shrinklist:\n",
    "            for bins in [28]:\n",
    "                if augment_with_profile_lenght:\n",
    "                    #le = preprocessing.KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='kmeans')\n",
    "                    #X = np.reshape(np.ediff1d(URM_train.indptr), (-1, 1))\n",
    "                    #le.fit_transform(X)\n",
    "                    #classList = le.transform(X)\n",
    "                    classList = np.ediff1d(URM_train.indptr)//2\n",
    "                    ones = np.ones(len(classList))\n",
    "                    UCM_profile = coo_matrix((ones, (np.arange(0, URM_train.shape[0]), classList)))\n",
    "                    UCM_profile = UCM_profile.tocsr()\n",
    "                    UCM_mod = sps.hstack([UCM, UCM_profile.multiply(3)], format='csr')\n",
    "                    userKNNCBF = UserKNNCBFRecommender(URM_train, UCM_mod)\n",
    "                else:\n",
    "                    userKNNCBF = UserKNNCBFRecommender(URM_train, UCM)\n",
    "                userKNNCBF.fit(shrink=sr, topK = tk, similarity = 'cosine')\n",
    "                if eval:\n",
    "                    dict_scores = (evalTest.evaluateRecommender(userKNNCBF))[0][10]\n",
    "                    MAP_LIST.append(('topK, shrink, bins :' + str(tk) + ' ' + str(sr) + ' '+str(bins), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        print(MAP_LIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#ICM_pop = coo_matrix((np.ones(len(item_pop)), (np.arange(0, URM_train.shape[1]), item_pop)))\n",
    "#profile_length = np.ediff1d(URM_train.indptr)\n",
    "#UCM_profile = coo_matrix((np.ones(len(profile_length)), (np.arange(0, URM_train.shape[0]), profile_length)))\n",
    "#UCM_mod = sps.hstack([UCM, UCM_profile], format='csr')\n",
    "#ICM_mod = sps.hstack([ICM, ICM_pop], format='csr')\n",
    "\n",
    "#entropy = np.ediff1d(URM_train.tocsc().indptr)\n",
    "#ICM_pop = coo_matrix((np.ones(len(item_pop)), (np.arange(0, URM_train.shape[1]), item_pop)))\n",
    "#ICM_entropy = sps.hstack([ICM, ICM_pop], format='csr')\n",
    "\n",
    "#popularity_bias = URM_train.toarray().dot(item_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(popularity_bias//profile_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# LightFM Recommender\n",
    "if False:\n",
    "    from RecLib.LFMRec import LFM \n",
    "    lfm_rec = LFM(URM_train, None, ICM)\n",
    "    MAP_LIST = []\n",
    "    epochsList = [20]\n",
    "    batchSize = [50]\n",
    "    tklist = [10]\n",
    "    lrs = [0.05]\n",
    "    losses=['bpr', 'warp']\n",
    "\n",
    "    for epochsN in epochsList:\n",
    "        for loss in losses:\n",
    "            for tk in tklist:\n",
    "                for lr in lrs:\n",
    "                    do_not_display_hystory = lfm_rec.fit(epochs=epochsN, no_components=10,\n",
    "            k=5,\n",
    "            n=10,\n",
    "            learning_schedule=\"adagrad\",\n",
    "            loss=loss,\n",
    "            learning_rate=lr,\n",
    "            rho=0.95,\n",
    "            epsilon=1e-6,\n",
    "            item_alpha=0.0,\n",
    "            user_alpha=0.0,\n",
    "            max_sampled=10,\n",
    "            random_state=None, num_threads=1,\n",
    "            verbose=False)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(lfm_rec))[0][10]\n",
    "                        MAP_LIST.append(('epoch, loss, lr :' + str(epochsN) + ' ' + loss + ' '  + str(lr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Pm7oY2Zx6Soy",
    "outputId": "d56a6477-e677-4dbe-db85-49c119d4b348",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# UserKNN Collaborative Filtering\n",
    "if False:\n",
    "    from KNN.UserKNNCFRecommender import UserKNNCFRecommender \n",
    "    userKNNCF = UserKNNCFRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    tklist = [600]\n",
    "    shrinklist = [5]\n",
    "\n",
    "    for tk in tklist:\n",
    "        for sr in shrinklist:\n",
    "            userKNNCF.fit(shrink=sr, topK = tk, similarity = 'cosine')\n",
    "            if eval:\n",
    "                dict_scores = (evaluator_validation.evaluateRecommender(userKNNCF))[0][10]\n",
    "                MAP_LIST.append(('topK, shrink :' + str(tk) + ' ' + str(sr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 18495 ( 100 % ), 7846.60 column/sec, elapsed time 0.04 min\n"
     ]
    }
   ],
   "source": [
    "# ItemKNN Collaborative Filtering\n",
    "if True:\n",
    "    from KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "    itemKNN = ItemKNNCFRecommender(URM_train)\n",
    "    \n",
    "    MAP_LIST = []\n",
    "    normalize = [True]\n",
    "    tklist = [5]\n",
    "    shrinkList = [25]\n",
    "\n",
    "    for simil in normalize:\n",
    "        for tk in tklist:\n",
    "            for shrink in shrinkList:\n",
    "                itemKNN.fit(shrink=shrink, topK=tk, normalize=simil)\n",
    "                if eval:\n",
    "                    dict_scores = (evaluator_validation.evaluateRecommender(itemKNN))[0][10]\n",
    "                    MAP_LIST.append(('Normalize, topK, shrink :' + str(simil)+ ' ' + str(tk) + ' ' + str(shrink), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Based\n",
    "if True:\n",
    "    from GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "    p3alpha_rec = P3alphaRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    similList = [True]\n",
    "    tklist = [30]\n",
    "    alphaList = [0.4]\n",
    "\n",
    "    for simil in similList:\n",
    "        for tk in tklist:\n",
    "            for alpha in alphaList:\n",
    "                do_not_display_hystory = p3alpha_rec.fit(topK=tk, alpha=alpha, normalize_similarity=simil)\n",
    "                if eval:\n",
    "                    dict_scores = (evaluator_validation.evaluateRecommender(p3alpha_rec))[0][10]\n",
    "                    MAP_LIST.append(('Normalize, topK, alpha :' + str(simil)+ ' ' + str(tk) + ' ' + str(alpha), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    from GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "    p3beta_rec = RP3betaRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    betaList = [0.1]\n",
    "    similList = [True]\n",
    "    tklist = [50]\n",
    "    alphaList = [0.4]\n",
    "\n",
    "    for beta in betaList:\n",
    "        for simil in similList:\n",
    "            for tk in tklist:\n",
    "                for alpha in alphaList:\n",
    "                    do_not_display_hystory = p3beta_rec.fit(topK=tk, alpha=alpha, beta=beta, normalize_similarity=simil)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(p3beta_rec))[0][10]\n",
    "                        MAP_LIST.append(('Normalize, topK, alpha, beta :' + str(simil)+ ' ' + str(tk) + ' ' + str(alpha) + ' ' + str(beta), dict_scores['MAP']))\n",
    "\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFW_D_Similarity_Linalg: Generating train data\n",
      "Similarity column 18495 ( 100 % ), 5205.45 column/sec, elapsed time 0.06 min\n",
      "CFW_D_Similarity_Linalg: Collaborative S density: 2.22E-04, nonzero cells 76015\n",
      "CFW_D_Similarity_Linalg: Content S density: 3.75E-02, nonzero cells 12828039\n",
      "CFW_D_Similarity_Linalg: Content S structure has 10409 out of 12828039 ( 0.08%) nonzero collaborative cells\n",
      "CFW_D_Similarity_Linalg: Nonzero collaborative cell sum is: 7.50E+02, average is: 7.20E-02, average over all collaborative data is 4.73E-02\n",
      "Similarity column 18495 ( 100 % ), 5790.51 column/sec, elapsed time 0.05 min\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from FeatureWeighting.CFW_D_Similarity_Linalg import CFW_D_Similarity_Linalg\n",
    "    W_sparse_CF = itemKNN.W_sparse\n",
    "    CFW_weithing = CFW_D_Similarity_Linalg(URM_train, ICM_mod, W_sparse_CF)\n",
    "    MAP_LIST = []\n",
    "    quotas = [0.1]\n",
    "    similList = [False]\n",
    "    tklist = [700]\n",
    "\n",
    "    for quota in quotas:\n",
    "        for normalization in similList:\n",
    "            for tk in tklist:  \n",
    "                    CFW_weithing.fit(topK = tk, add_zeros_quota = quota, normalize_similarity = normalization)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(CFW_weithing))[0][10]\n",
    "                        MAP_LIST.append(('Normalize, topK, quota :' + str(normalization)+ ' ' + str(tk) + ' ' + str(quota), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hybrid Recommender\n",
    "#hybridList = []\n",
    "from RecLib.HybridRecommender import *\n",
    "if True:\n",
    "    params = [(0.7, 0.3, 0.4, 0.05, 0.5, 1, 2 , 0.5)]\n",
    "    MAP_LIST = []\n",
    "    for param in params:\n",
    "                hybridrecommender = HybridRecommender(URM_train, userKNNCBF, itemKNN, itemKNNCBF, slim_rec, pureSVD, p3alpha_rec, p3beta_rec, SLIMElasticNet, CFW_weithing)\n",
    "                hybridrecommender.fit(*param)\n",
    "                if eval:\n",
    "                    dict_scores = (evaluator_validation.evaluateRecommender(hybridrecommender))[0][10]\n",
    "                    MAP_LIST.append(('params :' + str(param), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate performance of a recommender against users with 0,1,...,itrMax interactions\n",
    "rec_to_eval = userKNNCBF\n",
    "itrMax = 2\n",
    "\n",
    "if eval:\n",
    "    evaluateAgainstUsers(rec_to_eval, itrMax, URM_train, URM_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Compare different recommenders\n",
    "recommendersToCompare = [hybridrecommender, itemKNN, SLIMElasticNet, userKNNCBF]\n",
    "\n",
    "if eval:\n",
    "    from RecLib.Evaluate import *\n",
    "    compare(URM_train, URM_test, recommendersToCompare, enableTop = True, enablePureSVD = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYQRvvikMJVN",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "final_Rec = hybridrecommender\n",
    "\n",
    "if not eval:\n",
    "    output = []\n",
    "    for user_id in target_users:\n",
    "        output.append((user_id, final_Rec.recommend(user_id, cutoff=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5TyQsg9TAwz",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Writedown results\n",
    "\n",
    "if not eval:\n",
    "    import csv\n",
    "    with open('submission.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"user_id\", \"item_list\"])\n",
    "        for row in output:\n",
    "          ranking = ''\n",
    "          for val in row[1]:\n",
    "            ranking = ranking + str(val) + ' '\n",
    "          writer.writerow([row[0], ranking[:-1]])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sacajrota.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
