{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "7Ifkd08Lq3wR",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## RECSYS CHALLENGE 2020 ##\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from Notebooks_utils.data_splitter import train_test_holdout\n",
    "\n",
    "# Evaluation or scoring?\n",
    "eval = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mDejDEXq3wW",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Loading from CSV files...\n",
    "from RecLib.DataLoad import *\n",
    "UCM_age, ICM_subclass, ICM_asset, ICM_price, UCM_region, target_users, URM = dataLoad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4FzKl-xq3wc",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "URM = URM.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aODXsh3XsyJA",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Split dataset (train % of .9999 gives similar performance on test set and competition set)\n",
    "URM_train, URM_test = train_test_holdout(URM, train_perc = 0.8)\n",
    "\n",
    "if not eval:\n",
    "    URM_train = URM\n",
    "else:\n",
    "    from Base.Evaluation.Evaluator import EvaluatorHoldout\n",
    "    from RecLib.Evaluate import *\n",
    "    evaluator_validation = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load Item & User Content matrix\n",
    "ICM, UCM = contentMatrixLoad(URM_train, ICM_subclass, ICM_price, ICM_asset, UCM_age, UCM_region, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    from SLIM_ElasticNet.SLIMElasticNetRecommender import SLIMElasticNetRecommender\n",
    "    SLIMElasticNet = SLIMElasticNetRecommender(URM_train.tocsr())\n",
    "    if True or not eval:\n",
    "        MAP_LIST = []\n",
    "        tklist = [60]\n",
    "        penalties = [1]\n",
    "        alphas = [1e-4]\n",
    "        tol = [1e-5]\n",
    "        max_iter = [100]\n",
    "        positives = [True]\n",
    "        warm_start = [True]\n",
    "        for tk in tklist:\n",
    "            for penalty in penalties:\n",
    "                for alpha in alphas:\n",
    "                    for t in tol:\n",
    "                        for iters in max_iter:\n",
    "                            for positivity in positives:\n",
    "                                for ws in warm_start:\n",
    "                                    SLIMElasticNet.fit(l1_ratio=penalty, alpha = alpha, positive_only=positivity, topK = tk, warm_start = ws,tol = 1e-4, max_iter=100)\n",
    "                                    if eval:\n",
    "                                        dict_scores = (evaluator_validation.evaluateRecommender(SLIMElasticNet))[0][10]\n",
    "                                        MAP_LIST.append(('tol, positives, warm_start, iterations :' + str(t) + ' ' + str(positivity) + ' ' + str(ws) + ' ' + str(iters), dict_scores['MAP']))\n",
    "        if eval:\n",
    "            sortMap(MAP_LIST)\n",
    "        SLIMElasticNet.save_model('.')\n",
    "    else:\n",
    "        SLIMElasticNet.load_model('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SLIM BPR Recommender\n",
    "if True:\n",
    "    from SLIM_BPR.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython \n",
    "    slim_rec = SLIM_BPR_Cython(URM_train, recompile_cython=False, verbose = False)\n",
    "    MAP_LIST = []\n",
    "    epochsList = [300]\n",
    "    batchSize = [50]\n",
    "    tklist = [10]\n",
    "    lrs = [1e-3]\n",
    "\n",
    "    for epochsN in epochsList:\n",
    "        for bs in batchSize:\n",
    "            for tk in tklist:\n",
    "                for lr in lrs:\n",
    "                    do_not_display_hystory = slim_rec.fit(epochs=epochsN, batch_size=bs, sgd_mode='adagrad', learning_rate=lr, topK = tk)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(slim_rec))[0][10]\n",
    "                        MAP_LIST.append(('epoch, batch, topK, lr :' + str(epochsN) + ' ' + str(bs)+ ' ' + str(tk) + ' ' + str(lr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 18495 ( 100 % ), 9237.09 column/sec, elapsed time 0.03 min\n",
      "EvaluatorHoldout: Processed 20335 ( 100.00% ) in 9.67 sec. Users per second: 2103\n",
      "('topK, shrink, bins :3 10 5', 0.01380680616553551)\n"
     ]
    }
   ],
   "source": [
    "# ItemKNN Content Based Filtering\n",
    "if True:\n",
    "    from sklearn import preprocessing\n",
    "    from KNN.ItemKNNCBFRecommender import ItemKNNCBFRecommender \n",
    "    MAP_LIST = []\n",
    "    tklist = [3]\n",
    "    shrinklist = [10]\n",
    "    for bins in [5]:\n",
    "        for tk in tklist:\n",
    "            for sr in shrinklist:\n",
    "                le = preprocessing.KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='kmeans')\n",
    "                X = np.reshape(np.ediff1d(URM_train.tocsc().indptr), (-1, 1))\n",
    "                le.fit_transform(X)\n",
    "                classList = le.transform(X)\n",
    "                ones = np.ones(len(classList))\n",
    "                ICM_pop = coo_matrix((ones, (np.arange(0, URM_train.shape[1]), classList.reshape(-1,))), shape=(URM_train.shape[1], bins))\n",
    "                ICM_pop = ICM_pop.tocsr()\n",
    "                ICM_mod = sps.hstack([ICM, ICM_pop], format='csr')\n",
    "                itemKNNCBF = ItemKNNCBFRecommender(URM_train, ICM_mod)\n",
    "                itemKNNCBF.fit(shrink=sr, topK = tk, similarity = 'cosine')\n",
    "                if eval:\n",
    "                    dict_scores = (evaluator_validation.evaluateRecommender(itemKNNCBF))[0][10]\n",
    "                    MAP_LIST.append(('topK, shrink, bins :' + str(tk) + ' ' + str(sr) + ' '+str(bins), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    from MatrixFactorization.PureSVDRecommender import PureSVDRecommender \n",
    "    pureSVD = PureSVDRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    nfactorlist = [400]\n",
    "\n",
    "    for n in nfactorlist:\n",
    "        pureSVD.fit(num_factors=n, random_seed = None)\n",
    "        if eval:\n",
    "            dict_scores = (evaluator_validation.evaluateRecommender(pureSVD))[0][10]\n",
    "            MAP_LIST.append(('num factors :' + str(n) , dict_scores['MAP']))\n",
    "    if eval:\n",
    "        print(MAP_LIST)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 26641 Users\n",
      "Similarity column 30911 ( 100 % ), 1943.81 column/sec, elapsed time 0.27 min\n",
      "EvaluatorHoldout: Processed 614 ( 100.00% ) in 0.64 sec. Users per second: 964\n",
      "[('topK, shrink, bins :2500 10 106', 0.014604553366768353)]\n"
     ]
    }
   ],
   "source": [
    "# UserKNN Content Based Filtering\n",
    "augment_with_profile_lenght = False\n",
    "\n",
    "if eval:\n",
    "    to_compute_mask = np.ediff1d(URM_train.tocsr().indptr) == 0\n",
    "    to_ignore_mask = np.invert(to_compute_mask)\n",
    "    to_ignore = np.arange(URM_train.shape[0])[to_ignore_mask]\n",
    "    evalTest = EvaluatorHoldout(URM_test, cutoff_list=[10], ignore_users=to_ignore)\n",
    "\n",
    "if True:\n",
    "    from KNN.UserKNNCBFRecommender import UserKNNCBFRecommender \n",
    "    MAP_LIST = []\n",
    "    tklist = [2500]\n",
    "    shrinklist = [10]\n",
    "    \n",
    "    for tk in tklist:\n",
    "        for sr in shrinklist:\n",
    "            for bins in [106]:\n",
    "                if augment_with_profile_lenght:\n",
    "                    le = preprocessing.KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='kmeans')\n",
    "                    X = np.reshape(np.ediff1d(URM_train.indptr), (-1, 1))\n",
    "                    le.fit_transform(X)\n",
    "                    classList = le.transform(X)\n",
    "                    ones = np.ones(len(classList))\n",
    "                    UCM_profile = coo_matrix((ones, (np.arange(0, URM_train.shape[0]), classList.reshape(-1,))), shape=(URM_train.shape[0], bins))\n",
    "                    UCM_profile = UCM_profile.tocsr()\n",
    "                    UCM_mod = sps.hstack([UCM, UCM_profile], format='csr')\n",
    "                    userKNNCBF = UserKNNCBFRecommender(URM_train, UCM_mod)\n",
    "                else:\n",
    "                    userKNNCBF = UserKNNCBFRecommender(URM_train, UCM)\n",
    "                userKNNCBF.fit(shrink=sr, topK = tk, similarity = 'cosine')\n",
    "                if eval:\n",
    "                    dict_scores = (evalTest.evaluateRecommender(userKNNCBF))[0][10]\n",
    "                    MAP_LIST.append(('topK, shrink, bins :' + str(tk) + ' ' + str(sr) + ' '+str(bins), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        print(MAP_LIST)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#ICM_pop = coo_matrix((np.ones(len(item_pop)), (np.arange(0, URM_train.shape[1]), item_pop)))\n",
    "#profile_length = np.ediff1d(URM_train.indptr)\n",
    "#UCM_profile = coo_matrix((np.ones(len(profile_length)), (np.arange(0, URM_train.shape[0]), profile_length)))\n",
    "#UCM_mod = sps.hstack([UCM, UCM_profile], format='csr')\n",
    "#ICM_mod = sps.hstack([ICM, ICM_pop], format='csr')\n",
    "\n",
    "#entropy = np.ediff1d(URM_train.tocsc().indptr)\n",
    "#ICM_pop = coo_matrix((np.ones(len(item_pop)), (np.arange(0, URM_train.shape[1]), item_pop)))\n",
    "#ICM_entropy = sps.hstack([ICM, ICM_pop], format='csr')\n",
    "\n",
    "#popularity_bias = URM_train.toarray().dot(item_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(popularity_bias//profile_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 13001 ( 63.93% ) in 31.04 sec. Users per second: 419\n",
      "EvaluatorHoldout: Processed 20335 ( 100.00% ) in 45.53 sec. Users per second: 447\n",
      "EvaluatorHoldout: Processed 13001 ( 63.93% ) in 31.37 sec. Users per second: 414\n",
      "EvaluatorHoldout: Processed 20335 ( 100.00% ) in 46.02 sec. Users per second: 442\n",
      "('epoch, loss, lr :20 warp 0.05', 0.0002989437116631022)\n",
      "('epoch, loss, lr :20 bpr 0.05', 0.006133635959916304)\n"
     ]
    }
   ],
   "source": [
    "# LightFM Recommender\n",
    "if False:\n",
    "    from RecLib.LFMRec import LFM \n",
    "    lfm_rec = LFM(URM_train, None, ICM)\n",
    "    MAP_LIST = []\n",
    "    epochsList = [20]\n",
    "    batchSize = [50]\n",
    "    tklist = [10]\n",
    "    lrs = [0.05]\n",
    "    losses=['bpr', 'warp']\n",
    "\n",
    "    for epochsN in epochsList:\n",
    "        for loss in losses:\n",
    "            for tk in tklist:\n",
    "                for lr in lrs:\n",
    "                    do_not_display_hystory = lfm_rec.fit(epochs=epochsN, no_components=10,\n",
    "            k=5,\n",
    "            n=10,\n",
    "            learning_schedule=\"adagrad\",\n",
    "            loss=loss,\n",
    "            learning_rate=lr,\n",
    "            rho=0.95,\n",
    "            epsilon=1e-6,\n",
    "            item_alpha=0.0,\n",
    "            user_alpha=0.0,\n",
    "            max_sampled=10,\n",
    "            random_state=None, num_threads=1,\n",
    "            verbose=False)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(lfm_rec))[0][10]\n",
    "                        MAP_LIST.append(('epoch, loss, lr :' + str(epochsN) + ' ' + loss + ' '  + str(lr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Pm7oY2Zx6Soy",
    "outputId": "d56a6477-e677-4dbe-db85-49c119d4b348",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# UserKNN Collaborative Filtering\n",
    "if False:\n",
    "    from KNN.UserKNNCFRecommender import UserKNNCFRecommender \n",
    "    userKNNCF = UserKNNCFRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    tklist = [600]\n",
    "    shrinklist = [5]\n",
    "\n",
    "    for tk in tklist:\n",
    "        for sr in shrinklist:\n",
    "            userKNNCF.fit(shrink=sr, topK = tk, similarity = 'cosine')\n",
    "            if eval:\n",
    "                dict_scores = (evaluator_validation.evaluateRecommender(userKNNCF))[0][10]\n",
    "                MAP_LIST.append(('topK, shrink :' + str(tk) + ' ' + str(sr), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ItemKNN Collaborative Filtering\n",
    "if True:\n",
    "    from KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "    itemKNN = ItemKNNCFRecommender(URM_train)\n",
    "    \n",
    "    MAP_LIST = []\n",
    "    normalize = [True]\n",
    "    tklist = [5]\n",
    "    shrinkList = [25]\n",
    "\n",
    "    for simil in normalize:\n",
    "        for tk in tklist:\n",
    "            for shrink in shrinkList:\n",
    "                itemKNN.fit(shrink=shrink, topK=tk, normalize=simil)\n",
    "                if eval:\n",
    "                    dict_scores = (evaluator_validation.evaluateRecommender(itemKNN))[0][10]\n",
    "                    MAP_LIST.append(('Normalize, topK, shrink :' + str(simil)+ ' ' + str(tk) + ' ' + str(shrink), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST REMOVE TOP POP\n",
    "if False:\n",
    "    hybridList = []\n",
    "    from Base.NonPersonalizedRecommender import TopPop\n",
    "    top = TopPop(URM_train)\n",
    "    top.fit()\n",
    "    from KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "\n",
    "\n",
    "    \n",
    "    MAP_LIST = []\n",
    "    normalize = [True]\n",
    "    tklist = [5]\n",
    "    shrinkList = [25]\n",
    "\n",
    "    for simil in normalize:\n",
    "        for tk in tklist:\n",
    "            for shrink in shrinkList:\n",
    "                for x in range(0, 11):\n",
    "                    itemKNN = ItemKNNCFRecommender(URM_train)\n",
    "                    itemKNN.filterTopPop = True\n",
    "                    itemKNN.filterTopPop_ItemsID = top.recommend(0, cutoff = x)\n",
    "                    itemKNN.RECOMMENDER_NAME = 'Item' + str(x)\n",
    "                    itemKNN.fit(shrink=shrink, topK=tk, normalize=simil)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(itemKNN))[0][10]\n",
    "                        MAP_LIST.append(('Normalize, topK, shrink, topKremoved :' + str(simil)+ ' ' + str(tk) + ' ' + str(shrink)+ ' ' + str(x), dict_scores['MAP']))\n",
    "                    hybridList.append(itemKNN)\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Based\n",
    "if True:\n",
    "    from GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "    p3alpha_rec = P3alphaRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    similList = [True]\n",
    "    tklist = [30]\n",
    "    alphaList = [0.4]\n",
    "\n",
    "    for simil in similList:\n",
    "        for tk in tklist:\n",
    "            for alpha in alphaList:\n",
    "                do_not_display_hystory = p3alpha_rec.fit(topK=tk, alpha=alpha, normalize_similarity=simil)\n",
    "                if eval:\n",
    "                    dict_scores = (evaluator_validation.evaluateRecommender(p3alpha_rec))[0][10]\n",
    "                    MAP_LIST.append(('Normalize, topK, alpha :' + str(simil)+ ' ' + str(tk) + ' ' + str(alpha), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    from GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "    p3beta_rec = RP3betaRecommender(URM_train)\n",
    "    MAP_LIST = []\n",
    "    betaList = [0.1]\n",
    "    similList = [True]\n",
    "    tklist = [50]\n",
    "    alphaList = [0.4]\n",
    "\n",
    "    for beta in betaList:\n",
    "        for simil in similList:\n",
    "            for tk in tklist:\n",
    "                for alpha in alphaList:\n",
    "                    do_not_display_hystory = p3beta_rec.fit(topK=tk, alpha=alpha, beta=beta, normalize_similarity=simil)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(p3beta_rec))[0][10]\n",
    "                        MAP_LIST.append(('Normalize, topK, alpha, beta :' + str(simil)+ ' ' + str(tk) + ' ' + str(alpha) + ' ' + str(beta), dict_scores['MAP']))\n",
    "\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    from FeatureWeighting.CFW_D_Similarity_Linalg import CFW_D_Similarity_Linalg\n",
    "    W_sparse_CF = itemKNN.W_sparse\n",
    "    CFW_weithing = CFW_D_Similarity_Linalg(URM_train, ICM, W_sparse_CF)\n",
    "    MAP_LIST = []\n",
    "    quotas = [0.1]\n",
    "    similList = [False]\n",
    "    tklist = [700]\n",
    "\n",
    "    for quota in quotas:\n",
    "        for normalization in similList:\n",
    "            for tk in tklist:  \n",
    "                    CFW_weithing.fit(topK = tk, add_zeros_quota = quota, normalize_similarity = normalization)\n",
    "                    if eval:\n",
    "                        dict_scores = (evaluator_validation.evaluateRecommender(CFW_weithing))[0][10]\n",
    "                        MAP_LIST.append(('Normalize, topK, quota :' + str(normalization)+ ' ' + str(tk) + ' ' + str(quota), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hybrid Recommender\n",
    "#hybridList = []\n",
    "from RecLib.HybridRecommender import *\n",
    "if True:\n",
    "    params = [(0.7, 0.1, 0.4, 0.05, 0.5, 1, 2 , 0.5)]\n",
    "    MAP_LIST = []\n",
    "    for param in params:\n",
    "                hybridrecommender = HybridRecommender(URM_train, userKNNCBF, itemKNN, itemKNNCBF, slim_rec, pureSVD, p3alpha_rec, p3beta_rec, SLIMElasticNet, CFW_weithing)\n",
    "                hybridrecommender.fit(*param)\n",
    "                if eval:\n",
    "                    dict_scores = (evaluator_validation.evaluateRecommender(hybridrecommender))[0][10]\n",
    "                    MAP_LIST.append(('params :' + str(param), dict_scores['MAP']))\n",
    "    if eval:\n",
    "        sortMap(MAP_LIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 26568 Users\n",
      "EvaluatorHoldout: Processed 687 ( 100.00% ) in 0.68 sec. Users per second: 1005\n",
      "MAP at 0 interactions: 0.011992560245835355\n",
      "EvaluatorHoldout: Ignoring 27843 Users\n",
      "EvaluatorHoldout: Processed 842 ( 100.00% ) in 0.77 sec. Users per second: 1096\n",
      "MAP at 1 interactions: 0.009028131244580174\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of a recommender against users with 0,1,...,itrMax interactions\n",
    "rec_to_eval = userKNNCBF\n",
    "itrMax = 2\n",
    "\n",
    "if eval:\n",
    "    evaluateAgainstUsers(rec_to_eval, itrMax, URM_train, URM_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Compare different recommenders\n",
    "recommendersToCompare = [hybridrecommender]\n",
    "\n",
    "if eval:\n",
    "    from RecLib.Evaluate import *\n",
    "    compare(URM_train, URM_test, recommendersToCompare, enableTop = False, enablePureSVD = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYQRvvikMJVN",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "final_Rec = hybridrecommender\n",
    "\n",
    "if not eval:\n",
    "    output = []\n",
    "    for user_id in target_users:\n",
    "        output.append((user_id, final_Rec.recommend(user_id, cutoff=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5TyQsg9TAwz",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Writedown results\n",
    "\n",
    "if not eval:\n",
    "    import csv\n",
    "    with open('submission.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"user_id\", \"item_list\"])\n",
    "        for row in output:\n",
    "          ranking = ''\n",
    "          for val in row[1]:\n",
    "            ranking = ranking + str(val) + ' '\n",
    "          writer.writerow([row[0], ranking[:-1]])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sacajrota.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
